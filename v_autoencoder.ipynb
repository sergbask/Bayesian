{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-28T00:58:27.762242Z",
     "start_time": "2025-02-28T00:58:25.692160Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from datasets import Dataset, load_from_disk\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T01:01:55.744246Z",
     "start_time": "2025-02-28T01:01:55.742609Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 512",
   "id": "1f62258dcfedd3d8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T01:01:55.988720Z",
     "start_time": "2025-02-28T01:01:55.986207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "id": "1bbd08fbf9392a4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T01:01:56.209694Z",
     "start_time": "2025-02-28T01:01:56.204024Z"
    }
   },
   "cell_type": "code",
   "source": "df = load_from_disk(\"./data/encoded34\", keep_in_memory=False)",
   "id": "8a3c00851b079665",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:28:10.597467Z",
     "start_time": "2025-03-01T22:28:10.588873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder (VAE) class.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Dimensionality of the input data.\n",
    "        hidden_dim (int): Dimensionality of the hidden layer.\n",
    "        latent_dim (int): Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "                \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 8),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 8, latent_dim*2), # 2 for mean and variance.\n",
    "        )\n",
    "        # self.parametr = nn.Linear(latent_dim, 2 * latent_dim)\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 8),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 8, hidden_dim // 4),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 2),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Encodes the input data into the latent space.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            eps (float): Small value to avoid numerical instability.\n",
    "        \n",
    "        Returns:\n",
    "            torch.distributions.MultivariateNormal: Normal distribution of the encoded data.\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        # x = self.parametr(lat_x)\n",
    "        mu, logvar = torch.chunk(x, 2, dim=-1)\n",
    "        scale = self.softplus(logvar) + eps\n",
    "        scale_tril = torch.diag_embed(scale)\n",
    "        \n",
    "        return torch.distributions.MultivariateNormal(mu, scale_tril=scale_tril)\n",
    "        \n",
    "    def reparameterize(self, dist):\n",
    "        \"\"\"\n",
    "        Reparameterizes the encoded data to sample from the latent space.\n",
    "        \n",
    "        Args:\n",
    "            dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
    "        Returns:\n",
    "            torch.Tensor: Sampled data from the latent space.\n",
    "        \"\"\"\n",
    "        return dist.rsample()\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes the data from the latent space to the original input space.\n",
    "        \n",
    "        Args:\n",
    "            z (torch.Tensor): Data in the latent space.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed data in the original input space.\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the VAE.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            compute_loss (bool): Whether to compute the loss or not.\n",
    "        \n",
    "        Returns:\n",
    "            VAEOutput: VAE output dataclass.\n",
    "        \"\"\"\n",
    "        dist = self.encode(x)\n",
    "        z = self.reparameterize(dist)\n",
    "        recon_x = self.decode(z)\n",
    "        \n",
    "        # compute loss terms \n",
    "        loss_recon = F.mse_loss(recon_x, x, reduction='none').sum(-1).sqrt()#.mean()\n",
    "        std_normal = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros_like(z, device=z.device),\n",
    "            scale_tril=torch.eye(z.shape[-1], device=z.device).unsqueeze(0).expand(z.shape[0], -1, -1),\n",
    "        )\n",
    "        loss_kl = torch.distributions.kl.kl_divergence(dist, std_normal)#.mean()\n",
    "        # loss_kl = F.kl_div(z, lat_x, reduction='none').mean()\n",
    "                \n",
    "        loss = loss_recon + loss_kl\n",
    "        \n",
    "        return loss.mean(),loss_recon"
   ],
   "id": "f6f2a901aa855a21",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T03:42:54.650295Z",
     "start_time": "2025-03-01T03:42:54.646288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VAE1(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=200, device=device):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        \n",
    "        # latent mean and variance \n",
    "        self.mean_layer = nn.Linear(latent_dim, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(latent_dim, latent_dim),\n",
    "            # nn.LeakyReLU(0.2),\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            )\n",
    "     \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var)#.to(device)      \n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar"
   ],
   "id": "fb6c570a1bf33a25",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:33:17.384507Z",
     "start_time": "2025-03-01T19:33:17.328645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vae_mod = VAE(input_dim=512, hidden_dim=256, latent_dim=32)\n",
    "x = torch.randn((3, 512), requires_grad=True).to(device)\n",
    "model_auto(x)"
   ],
   "id": "ac7b0b8001d4b691",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24.0779, 23.0352, 21.3502], device='mps:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T03:43:01.029836Z",
     "start_time": "2025-03-01T03:43:01.026392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReproductionKLDLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, x_hat, mean, log_var):\n",
    "        reproduction_loss = self.criterion(x_hat, x)\n",
    "        KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "        return reproduction_loss + KLD"
   ],
   "id": "395b0f9ecf60f422",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T17:29:52.723325Z",
     "start_time": "2025-03-01T17:29:52.721344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = df['train']\n",
    "df_test = df['test']\n",
    "dataloader_train = DataLoader(df_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(df_test, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ],
   "id": "8e36718bebab013f",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T17:29:53.177017Z",
     "start_time": "2025-03-01T17:29:53.170884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts = next(iter(dataloader_train))\n",
    "ts"
   ],
   "id": "a6312dcc0cf82a7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2930, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0136, 0.6613, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1455, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2669, 0.2220],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0600, 0.0895]])}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T17:29:54.602765Z",
     "start_time": "2025-03-01T17:29:54.599945Z"
    }
   },
   "cell_type": "code",
   "source": "ts['data'].size()",
   "id": "c52204f6e16da732",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:58:49.434094Z",
     "start_time": "2025-03-02T02:58:49.429452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop(model, dataloader_train, dataloader_test, nf):\n",
    "    best_vloss = 1e+10\n",
    "    # bs = dataloader_train.batch_size\n",
    "    bntr, bntst = len(dataloader_train), len(dataloader_test)\n",
    "\n",
    "    learning_rate = 1e-1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = ReproductionKLDLoss()\n",
    "    n_epoch = 1000\n",
    "\n",
    "    for epoch in range(1, n_epoch+1):\n",
    "        model.train()\n",
    "        loss_train = 0.0\n",
    "        for itms in dataloader_train:\n",
    "            x=itms['data']\n",
    "            batch_size = x.shape[0]\n",
    "            x = x.to(device)\n",
    "            # lables = lables.to(device)\n",
    "            # x_hat, mean, logvar = model(x)\n",
    "            # loss = loss_fn(x, x_hat, mean, logvar)\n",
    "            loss = model(x)[0]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        loss_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for itms in dataloader_test:\n",
    "                x=itms['data']\n",
    "                x = x.to(device)\n",
    "                # x_hat, mean, logvar = model(x)\n",
    "                # loss_v = loss_fn(x, x_hat, mean, logvar)\n",
    "                loss_v = model(x)[0]\n",
    "                loss_val += loss_v.item()\n",
    "        #     \n",
    "            if loss_val < best_vloss:\n",
    "                torch.save(model.state_dict(), nf)\n",
    "                best_vloss = loss_val\n",
    "\n",
    "\n",
    "    \n",
    "        if epoch == 1 or epoch%10 == 0:\n",
    "            print(f'Epoch: {epoch}, Epoch train loss: {loss_train/bntr}')\n",
    "            print(f'Epoch val loss: {loss_val/bntst}')\n",
    "            # print(f'Accuracy: {correct/total*100}')\n",
    "            \n",
    "    return best_vloss"
   ],
   "id": "25833769172aab50",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:50:14.120114Z",
     "start_time": "2025-03-01T19:50:14.118324Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cbeec113176cd834",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:28:43.900721Z",
     "start_time": "2025-03-01T22:28:43.882592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del model_auto\n",
    "model_auto = VAE(input_dim=512, hidden_dim=256, latent_dim=32).to(device)"
   ],
   "id": "8645159f0b2ffa8e",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T20:15:17.821027Z",
     "start_time": "2025-03-01T19:50:16.435411Z"
    }
   },
   "cell_type": "code",
   "source": "training_loop(model_auto, dataloader_train, dataloader_test, nf='best_model_var_autoenc32_resnet34.pt')",
   "id": "14182947f7bb022f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Epoch train loss: 1792582.8856171828\n",
      "Epoch val loss: 85570.1328125\n",
      "Epoch: 10, Epoch train loss: 13.65986288510836\n",
      "Epoch val loss: 12.877128601074219\n",
      "Epoch: 20, Epoch train loss: 6.46165840442364\n",
      "Epoch val loss: 6.174883842468262\n",
      "Epoch: 30, Epoch train loss: 5.615176457625169\n",
      "Epoch val loss: 5.402649879455566\n",
      "Epoch: 40, Epoch train loss: 5.366783839005691\n",
      "Epoch val loss: 5.377449035644531\n",
      "Epoch: 50, Epoch train loss: 5.319763697110689\n",
      "Epoch val loss: 5.287500381469727\n",
      "Epoch: 60, Epoch train loss: 5.294936436873216\n",
      "Epoch val loss: 5.28904914855957\n",
      "Epoch: 70, Epoch train loss: 5.280575788938082\n",
      "Epoch val loss: 5.282448768615723\n",
      "Epoch: 80, Epoch train loss: 5.278001895317664\n",
      "Epoch val loss: 5.168530464172363\n",
      "Epoch: 90, Epoch train loss: 5.274139771094689\n",
      "Epoch val loss: 5.213235855102539\n",
      "Epoch: 100, Epoch train loss: 5.274828140552227\n",
      "Epoch val loss: 5.282842636108398\n",
      "Epoch: 110, Epoch train loss: 5.273965798891508\n",
      "Epoch val loss: 5.241713047027588\n",
      "Epoch: 120, Epoch train loss: 5.27522061421321\n",
      "Epoch val loss: 5.178433418273926\n",
      "Epoch: 130, Epoch train loss: 5.281300324660081\n",
      "Epoch val loss: 5.246149063110352\n",
      "Epoch: 140, Epoch train loss: 5.270947162921612\n",
      "Epoch val loss: 5.243227958679199\n",
      "Epoch: 150, Epoch train loss: 5.271289128523606\n",
      "Epoch val loss: 5.256047248840332\n",
      "Epoch: 160, Epoch train loss: 5.277008680196909\n",
      "Epoch val loss: 5.262476921081543\n",
      "Epoch: 170, Epoch train loss: 5.2763022276071405\n",
      "Epoch val loss: 5.260350227355957\n",
      "Epoch: 180, Epoch train loss: 5.278865410731389\n",
      "Epoch val loss: 5.308547019958496\n",
      "Epoch: 190, Epoch train loss: 5.276831113375151\n",
      "Epoch val loss: 5.20933723449707\n",
      "Epoch: 200, Epoch train loss: 5.277181001809927\n",
      "Epoch val loss: 5.208310604095459\n",
      "Epoch: 210, Epoch train loss: 5.278970645024226\n",
      "Epoch val loss: 5.209588050842285\n",
      "Epoch: 220, Epoch train loss: 5.272187929887038\n",
      "Epoch val loss: 5.265589237213135\n",
      "Epoch: 230, Epoch train loss: 5.278145019824688\n",
      "Epoch val loss: 5.197940826416016\n",
      "Epoch: 240, Epoch train loss: 5.2971601119408245\n",
      "Epoch val loss: 5.252664566040039\n",
      "Epoch: 250, Epoch train loss: 5.2762603392967815\n",
      "Epoch val loss: 5.2641215324401855\n",
      "Epoch: 260, Epoch train loss: 5.277204880347619\n",
      "Epoch val loss: 5.242494583129883\n",
      "Epoch: 270, Epoch train loss: 5.272678705362173\n",
      "Epoch val loss: 5.240074634552002\n",
      "Epoch: 280, Epoch train loss: 5.27639337686392\n",
      "Epoch val loss: 5.322256088256836\n",
      "Epoch: 290, Epoch train loss: 5.2679512317364035\n",
      "Epoch val loss: 5.133469581604004\n",
      "Epoch: 300, Epoch train loss: 5.274786252241868\n",
      "Epoch val loss: 5.227480888366699\n",
      "Epoch: 310, Epoch train loss: 5.271660621349628\n",
      "Epoch val loss: 5.206750392913818\n",
      "Epoch: 320, Epoch train loss: 5.271513131948618\n",
      "Epoch val loss: 5.237642288208008\n",
      "Epoch: 330, Epoch train loss: 5.278229456681472\n",
      "Epoch val loss: 5.250222682952881\n",
      "Epoch: 340, Epoch train loss: 5.272888660430908\n",
      "Epoch val loss: 5.210858345031738\n",
      "Epoch: 350, Epoch train loss: 5.278094658484826\n",
      "Epoch val loss: 5.211421012878418\n",
      "Epoch: 360, Epoch train loss: 5.273528612576998\n",
      "Epoch val loss: 5.199804306030273\n",
      "Epoch: 370, Epoch train loss: 5.282322076650766\n",
      "Epoch val loss: 5.241966247558594\n",
      "Epoch: 380, Epoch train loss: 5.273339124826284\n",
      "Epoch val loss: 5.2322492599487305\n",
      "Epoch: 390, Epoch train loss: 5.278323870438796\n",
      "Epoch val loss: 5.207681179046631\n",
      "Epoch: 400, Epoch train loss: 5.277149090400109\n",
      "Epoch val loss: 5.179837226867676\n",
      "Epoch: 410, Epoch train loss: 5.272850880256066\n",
      "Epoch val loss: 5.216677188873291\n",
      "Epoch: 420, Epoch train loss: 5.2718114119309645\n",
      "Epoch val loss: 5.275375843048096\n",
      "Epoch: 430, Epoch train loss: 5.273335713606614\n",
      "Epoch val loss: 5.1796064376831055\n",
      "Epoch: 440, Epoch train loss: 5.275751627408541\n",
      "Epoch val loss: 5.240057945251465\n",
      "Epoch: 450, Epoch train loss: 5.271226846254789\n",
      "Epoch val loss: 5.251298904418945\n",
      "Epoch: 460, Epoch train loss: 5.275058306180513\n",
      "Epoch val loss: 5.312783718109131\n",
      "Epoch: 470, Epoch train loss: 5.275316018324632\n",
      "Epoch val loss: 5.26141881942749\n",
      "Epoch: 480, Epoch train loss: 5.271380681257981\n",
      "Epoch val loss: 5.224721908569336\n",
      "Epoch: 490, Epoch train loss: 5.273602192218487\n",
      "Epoch val loss: 5.244357109069824\n",
      "Epoch: 500, Epoch train loss: 5.279237710512602\n",
      "Epoch val loss: 5.240548133850098\n",
      "Epoch: 510, Epoch train loss: 5.278865080613357\n",
      "Epoch val loss: 5.2309393882751465\n",
      "Epoch: 520, Epoch train loss: 5.278263532198393\n",
      "Epoch val loss: 5.231419086456299\n",
      "Epoch: 530, Epoch train loss: 5.275430532602163\n",
      "Epoch val loss: 5.256426811218262\n",
      "Epoch: 540, Epoch train loss: 5.277516071613018\n",
      "Epoch val loss: 5.295259475708008\n",
      "Epoch: 550, Epoch train loss: 5.275559755472036\n",
      "Epoch val loss: 5.224377155303955\n",
      "Epoch: 560, Epoch train loss: 5.524103274712195\n",
      "Epoch val loss: 5.274650573730469\n",
      "Epoch: 570, Epoch train loss: 5.287509844853328\n",
      "Epoch val loss: 5.262773513793945\n",
      "Epoch: 580, Epoch train loss: 5.274612169999343\n",
      "Epoch val loss: 5.254720211029053\n",
      "Epoch: 590, Epoch train loss: 5.275234552530142\n",
      "Epoch val loss: 5.211670875549316\n",
      "Epoch: 600, Epoch train loss: 5.27411255469689\n",
      "Epoch val loss: 5.265508651733398\n",
      "Epoch: 610, Epoch train loss: 5.273147656367375\n",
      "Epoch val loss: 5.177053451538086\n",
      "Epoch: 620, Epoch train loss: 5.277656628535344\n",
      "Epoch val loss: 5.223215103149414\n",
      "Epoch: 630, Epoch train loss: 5.274002441993127\n",
      "Epoch val loss: 5.20341682434082\n",
      "Epoch: 640, Epoch train loss: 5.274772020486685\n",
      "Epoch val loss: 5.24915885925293\n",
      "Epoch: 650, Epoch train loss: 5.276420960059533\n",
      "Epoch val loss: 5.2721757888793945\n",
      "Epoch: 660, Epoch train loss: 5.276254470531757\n",
      "Epoch val loss: 5.214670181274414\n",
      "Epoch: 670, Epoch train loss: 5.275356696202205\n",
      "Epoch val loss: 5.265900611877441\n",
      "Epoch: 680, Epoch train loss: 5.2775870103102465\n",
      "Epoch val loss: 5.246806621551514\n",
      "Epoch: 690, Epoch train loss: 5.277974972358117\n",
      "Epoch val loss: 5.224294185638428\n",
      "Epoch: 700, Epoch train loss: 5.277345657348633\n",
      "Epoch val loss: 5.221577167510986\n",
      "Epoch: 710, Epoch train loss: 5.276033621567946\n",
      "Epoch val loss: 5.28804349899292\n",
      "Epoch: 720, Epoch train loss: 5.276715462024395\n",
      "Epoch val loss: 5.199801445007324\n",
      "Epoch: 730, Epoch train loss: 5.278083324432373\n",
      "Epoch val loss: 5.27938985824585\n",
      "Epoch: 740, Epoch train loss: 5.270104921781099\n",
      "Epoch val loss: 5.238899230957031\n",
      "Epoch: 750, Epoch train loss: 5.278806686401367\n",
      "Epoch val loss: 5.22504997253418\n",
      "Epoch: 760, Epoch train loss: 5.2717452782851\n",
      "Epoch val loss: 5.230488300323486\n",
      "Epoch: 770, Epoch train loss: 5.275431339557354\n",
      "Epoch val loss: 5.181328296661377\n",
      "Epoch: 780, Epoch train loss: 5.275112115419828\n",
      "Epoch val loss: 5.262825012207031\n",
      "Epoch: 790, Epoch train loss: 5.278252748342661\n",
      "Epoch val loss: 5.242497444152832\n",
      "Epoch: 800, Epoch train loss: 5.278915918790377\n",
      "Epoch val loss: 5.218549728393555\n",
      "Epoch: 810, Epoch train loss: 5.273755440345178\n",
      "Epoch val loss: 5.17683219909668\n",
      "Epoch: 820, Epoch train loss: 5.278085158421443\n",
      "Epoch val loss: 5.315465927124023\n",
      "Epoch: 830, Epoch train loss: 5.278847254239595\n",
      "Epoch val loss: 5.19929838180542\n",
      "Epoch: 840, Epoch train loss: 5.275398144355187\n",
      "Epoch val loss: 5.251119613647461\n",
      "Epoch: 850, Epoch train loss: 5.2709299967839165\n",
      "Epoch val loss: 5.221944808959961\n",
      "Epoch: 860, Epoch train loss: 5.269595292898325\n",
      "Epoch val loss: 5.2121171951293945\n",
      "Epoch: 870, Epoch train loss: 5.279378414154053\n",
      "Epoch val loss: 5.215831756591797\n",
      "Epoch: 880, Epoch train loss: 5.275883527902456\n",
      "Epoch val loss: 5.228155612945557\n",
      "Epoch: 890, Epoch train loss: 5.279645112844614\n",
      "Epoch val loss: 5.163166046142578\n",
      "Epoch: 900, Epoch train loss: 5.2766187741206245\n",
      "Epoch val loss: 5.27344274520874\n",
      "Epoch: 910, Epoch train loss: 5.2734503379234905\n",
      "Epoch val loss: 5.226099491119385\n",
      "Epoch: 920, Epoch train loss: 5.273592215317946\n",
      "Epoch val loss: 5.218731880187988\n",
      "Epoch: 930, Epoch train loss: 5.273142924675574\n",
      "Epoch val loss: 5.210237503051758\n",
      "Epoch: 940, Epoch train loss: 5.273129279796894\n",
      "Epoch val loss: 5.255125522613525\n",
      "Epoch: 950, Epoch train loss: 5.276465562673716\n",
      "Epoch val loss: 5.225668907165527\n",
      "Epoch: 960, Epoch train loss: 5.276409992804894\n",
      "Epoch val loss: 5.222338676452637\n",
      "Epoch: 970, Epoch train loss: 5.276370745438796\n",
      "Epoch val loss: 5.242336273193359\n",
      "Epoch: 980, Epoch train loss: 5.276726135840783\n",
      "Epoch val loss: 5.231369972229004\n",
      "Epoch: 990, Epoch train loss: 5.273992905249963\n",
      "Epoch val loss: 5.222634315490723\n",
      "Epoch: 1000, Epoch train loss: 5.281046317173884\n",
      "Epoch val loss: 5.16740608215332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.120736598968506"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:28:47.439508Z",
     "start_time": "2025-03-01T22:28:47.420102Z"
    }
   },
   "cell_type": "code",
   "source": "model_auto.load_state_dict(torch.load('best_model_var_autoenc32_resnet34.pt', map_location=device, weights_only=False))",
   "id": "c122bb723a65e237",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T03:44:01.489739Z",
     "start_time": "2025-03-01T03:44:01.479895Z"
    }
   },
   "cell_type": "code",
   "source": "len(model_auto(ts['data'].to(device)))",
   "id": "679e098cc360605b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T03:44:04.314597Z",
     "start_time": "2025-03-01T03:44:04.174734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# loss_fn = torch.nn.MSELoss(reduction='none')\n",
    "# torch.mean(loss_fn(model_auto(ts['data'].to(device))[0], ts['data'].to(device)), dim=1)#.size()"
   ],
   "id": "316502d19038c978",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1501, 0.0228, 0.0396, 0.0127, 0.0231, 0.1142, 0.0466, 0.0625, 0.0357,\n",
       "        0.0757, 0.0215, 0.0559, 0.0225, 0.0584, 0.1099, 0.0521, 0.0357, 0.0417,\n",
       "        0.0626, 0.0506, 0.0367, 0.0185, 0.0188, 0.1115, 0.0226, 0.0426, 0.0134,\n",
       "        0.0988, 0.0280, 0.0182, 0.0114, 0.0518, 0.1604, 0.0187, 0.0329, 0.0712,\n",
       "        0.0188, 0.0153, 0.1094, 0.0116, 0.0353, 0.0247, 0.0594, 0.0296, 0.0384,\n",
       "        0.0195, 0.0444, 0.0352, 0.0506, 0.0254, 0.0474, 0.0766, 0.0259, 0.0446,\n",
       "        0.0397, 0.0316, 0.0538, 0.2793, 0.0623, 0.0163, 0.0357, 0.0538, 0.0409,\n",
       "        0.0424, 0.0582, 0.0440, 0.0390, 0.0502, 0.0320, 0.0481, 0.0469, 0.0164,\n",
       "        0.0545, 0.0246, 0.0673, 0.0304, 0.1055, 0.0415, 0.0296, 0.0259, 0.0585,\n",
       "        0.0176, 0.0325, 0.0893, 0.0400, 0.0221, 0.0510, 0.0779, 0.0739, 0.0408,\n",
       "        0.0357, 0.1701, 0.0271, 0.0333, 0.0247, 0.0262, 0.0579, 0.0330, 0.0648,\n",
       "        0.0480, 0.0757, 0.0519, 0.0375, 0.0341, 0.0301, 0.0186, 0.1303, 0.0189,\n",
       "        0.0702, 0.0250, 0.0581, 0.0464, 0.2981, 0.0287, 0.0402, 0.0287, 0.0676,\n",
       "        0.0292, 0.0813, 0.0164, 0.0416, 0.0324, 0.0694, 0.0281, 0.0199, 0.0257,\n",
       "        0.0289, 0.0241, 0.0675, 0.0437, 0.0607, 0.0265, 0.0186, 0.0166, 0.0252,\n",
       "        0.0241, 0.1433, 0.0357, 0.0176, 0.0551, 0.0264, 0.0787, 0.0350, 0.1145,\n",
       "        0.0631, 0.0509, 0.0804, 0.0214, 0.0367, 0.0207, 0.0392, 0.0155, 0.0268,\n",
       "        0.0340, 0.0376, 0.0660, 0.0276, 0.0532, 0.0858, 0.0389, 0.0286, 0.0414,\n",
       "        0.0294, 0.0437, 0.0889, 0.0190, 0.0298, 0.0300, 0.1038, 0.0258, 0.0703,\n",
       "        0.0272, 0.0199, 0.0962, 0.0482, 0.0245, 0.0486, 0.0312, 0.0481, 0.0570,\n",
       "        0.0565, 0.0387, 0.0436, 0.0375, 0.0232, 0.0189, 0.0281, 0.0274, 0.0347,\n",
       "        0.0732, 0.0439, 0.0322, 0.0194, 0.0429, 0.0253, 0.0721, 0.0218, 0.0806,\n",
       "        0.0281, 0.0216, 0.0284, 0.0646, 0.0474, 0.0856, 0.1587, 0.0272, 0.0469,\n",
       "        0.0720, 0.0296, 0.0129, 0.0181, 0.0657, 0.0639, 0.0998, 0.0391, 0.0517,\n",
       "        0.0847, 0.0238, 0.0220, 0.0176, 0.0246, 0.0515, 0.0248, 0.0871, 0.0623,\n",
       "        0.0300, 0.0473, 0.0330, 0.0495, 0.0306, 0.1020, 0.0188, 0.0521, 0.0207,\n",
       "        0.0378, 0.0433, 0.0198, 0.1104, 0.0428, 0.0556, 0.0426, 0.0228, 0.0280,\n",
       "        0.0473, 0.0644, 0.0548, 0.0177, 0.0441, 0.0468, 0.0319, 0.0959, 0.0424,\n",
       "        0.0670, 0.0799, 0.0742, 0.0527, 0.1656, 0.0639, 0.0266, 0.0870, 0.0299,\n",
       "        0.1408, 0.0399, 0.0599, 0.0256, 0.0545, 0.0589, 0.0227, 0.0291, 0.0223,\n",
       "        0.0185, 0.0673, 0.0256, 0.0268, 0.0698, 0.0192, 0.0124, 0.0357, 0.1034,\n",
       "        0.0222, 0.0649, 0.0246, 0.0202, 0.0176, 0.0535, 0.0933, 0.0690, 0.0607,\n",
       "        0.0190, 0.0311, 0.0307, 0.0592, 0.0214, 0.0229, 0.0226, 0.0675, 0.0290,\n",
       "        0.0222, 0.0139, 0.0334, 0.0127, 0.0240, 0.0773, 0.0304, 0.0387, 0.0537,\n",
       "        0.0462, 0.2074, 0.0642, 0.0596, 0.0519, 0.0637, 0.0511, 0.0348, 0.0503,\n",
       "        0.0170, 0.0472, 0.0465, 0.1717, 0.0239, 0.0750, 0.0228, 0.0388, 0.1354,\n",
       "        0.0138, 0.0184, 0.0917, 0.0228, 0.0356, 0.0591, 0.0323, 0.1564, 0.0553,\n",
       "        0.0665, 0.0375, 0.0276, 0.0559, 0.0126, 0.0792, 0.0762, 0.0138, 0.0361,\n",
       "        0.0139, 0.0366, 0.0729, 0.0717, 0.0417, 0.0411, 0.0804, 0.0295, 0.0601,\n",
       "        0.0158, 0.0792, 0.0194, 0.0327, 0.0587, 0.0824, 0.0420, 0.0550, 0.0756,\n",
       "        0.0672, 0.0239, 0.0882, 0.1226, 0.1436, 0.0123, 0.0270, 0.0716, 0.0322,\n",
       "        0.0377, 0.0256, 0.0324, 0.0501, 0.0289, 0.0839, 0.0840, 0.0549, 0.0181,\n",
       "        0.0526, 0.0368, 0.0525, 0.0208, 0.0275, 0.0308, 0.0243, 0.0381, 0.0666,\n",
       "        0.0377, 0.0145, 0.0449, 0.0157, 0.0864, 0.0600, 0.0665, 0.0387, 0.0527,\n",
       "        0.0115, 0.0419, 0.0505, 0.0319, 0.0395, 0.0417, 0.0337, 0.0190, 0.0402,\n",
       "        0.0200, 0.0188, 0.0719, 0.0535, 0.0175, 0.0397, 0.0572, 0.0593, 0.0632,\n",
       "        0.0208, 0.0646, 0.0324, 0.0877, 0.0454, 0.0786, 0.0212, 0.0349, 0.0706,\n",
       "        0.0244, 0.0724, 0.0416, 0.0296, 0.0307, 0.0774, 0.0649, 0.0398, 0.0188,\n",
       "        0.0466, 0.0769, 0.0366, 0.0543, 0.0404, 0.0291, 0.0522, 0.0220, 0.0405,\n",
       "        0.0391, 0.0887, 0.0313, 0.0381, 0.0465, 0.0446, 0.0264, 0.0278, 0.0783,\n",
       "        0.0481, 0.0399, 0.0313, 0.0240, 0.0529, 0.0361, 0.0298, 0.0257, 0.0421,\n",
       "        0.0207, 0.0458, 0.0668, 0.0415, 0.0481, 0.0627, 0.0385, 0.0713, 0.0399,\n",
       "        0.0672, 0.0709, 0.1842, 0.0193, 0.0457, 0.0235, 0.0221, 0.0339, 0.0382,\n",
       "        0.0311, 0.0630, 0.0660, 0.0776, 0.0272, 0.0465, 0.0312, 0.0825, 0.0318,\n",
       "        0.0585, 0.0342, 0.0611, 0.0249, 0.0443, 0.0360, 0.0797, 0.0367, 0.0797,\n",
       "        0.0722, 0.0376, 0.0186, 0.0826, 0.0257, 0.0378, 0.0567, 0.0423, 0.0638,\n",
       "        0.0314, 0.0328, 0.0308, 0.0607, 0.0423, 0.0373, 0.0734, 0.0350],\n",
       "       device='mps:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T03:44:06.867552Z",
     "start_time": "2025-03-01T03:44:06.866040Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36349d4db00cfbc0",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:29:21.547178Z",
     "start_time": "2025-03-01T22:29:21.544245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_error(model, dataloader_train, dataloader_test):\n",
    "    # loss_fn = torch.nn.MSELoss(reduction='none')\n",
    "    errors = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for itms in dataloader_train:\n",
    "            x=itms['data']\n",
    "            batch_size = x.shape[0]\n",
    "            x = x.to(device)\n",
    "            # lables = lables.to(device)\n",
    "            outputs = model(x)[1]\n",
    "            error = outputs.cpu().tolist()\n",
    "            errors.extend(error)\n",
    "\n",
    "            # \n",
    "        for itms in dataloader_test:\n",
    "            x=itms['data']\n",
    "            x = x.to(device)\n",
    "            outputs = model(x)[1]\n",
    "            error = outputs.cpu().tolist()\n",
    "            errors.extend(error)\n",
    "\n",
    "            \n",
    "    return errors"
   ],
   "id": "4b50eea921d9536",
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:29:23.115697Z",
     "start_time": "2025-03-01T22:29:22.205861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "errors = extract_error(model_auto, dataloader_train, dataloader_test)\n",
    "len(errors)"
   ],
   "id": "bc26c067cf337651",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7168"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:29:24.670038Z",
     "start_time": "2025-03-01T22:29:24.606544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(errors, bins=100)\n",
    "plt.show()"
   ],
   "id": "57c39e2943ba118b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:29:27.707153Z",
     "start_time": "2025-03-01T22:29:27.703159Z"
    }
   },
   "cell_type": "code",
   "source": "np.mean(errors), np.std(errors)",
   "id": "41158a1ebf42eb86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(5.278999409804653), np.float64(1.6534977055762279))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "15b423ece04cdd2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:20:27.569173Z",
     "start_time": "2025-03-02T02:20:27.544460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del model_auto\n",
    "model_auto = VAE(input_dim=512, hidden_dim=256, latent_dim=64).to(device)"
   ],
   "id": "ff7273912c3e6b33",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:56:54.869871Z",
     "start_time": "2025-03-02T02:56:52.749179Z"
    }
   },
   "cell_type": "code",
   "source": "training_loop(model_auto, dataloader_train, dataloader_test, nf='best_model_var_autoenc64_resnet34.pt')",
   "id": "d5e8d05d05f1f71c",
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'best_vloss' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[184], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtraining_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_auto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbest_model_var_autoenc64_resnet34.pt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[183], line 41\u001B[0m, in \u001B[0;36mtraining_loop\u001B[0;34m(model, dataloader_train, dataloader_test, nf)\u001B[0m\n\u001B[1;32m     39\u001B[0m         loss_val \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss_v\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m#     \u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mloss_val\u001B[49m \u001B[38;5;241m<\u001B[39m best_vloss:\n\u001B[1;32m     42\u001B[0m         torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), nf)\n\u001B[1;32m     43\u001B[0m         best_vloss \u001B[38;5;241m=\u001B[39m loss_val\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: cannot access local variable 'best_vloss' where it is not associated with a value"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:57:26.903088Z",
     "start_time": "2025-03-02T02:57:26.886875Z"
    }
   },
   "cell_type": "code",
   "source": "model_auto.load_state_dict(torch.load('best_model_var_autoenc64_resnet34.pt', map_location=device, weights_only=False))",
   "id": "6a0bbe2bf5be54d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:57:29.012306Z",
     "start_time": "2025-03-02T02:57:27.843253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "errors = extract_error(model_auto, dataloader_train, dataloader_test)\n",
    "len(errors)"
   ],
   "id": "f28a8b4cc116f6e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7168"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:57:30.878688Z",
     "start_time": "2025-03-02T02:57:30.815344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(errors, bins=100)\n",
    "plt.show()"
   ],
   "id": "eccf2e418b5d50d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHahJREFUeJzt3QmwnfP9P/BPFiKWJE3IVomtSIitQaRUtUlFpNSItjR2wzCSkigStcUWW0ullup0LDOimLEUpU2DYMQWVYKmopZYkhiaXGJEuOc33+f/v7c5kfXKdb73nNdr5nHuOc9zz/2ex8257/P5Lk+rUqlUCgCAjLSudAMAAJYmoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkp220QPX19fHuu+/GBhtsEK1atap0cwCAVZDWhv3oo4+iZ8+e0bp16+oLKCmc9OrVq9LNAACaYPbs2bHxxhtXX0BJlZOGF9ihQ4dKNwcAWAV1dXVFgaHh73jVBZSGbp0UTgQUAGhZVmV4hkGyAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCy07bSDYDVsenY+7/02BsXD6tIWwBoPiooAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyY5ox2UwZNl0YgAYqKABAdgQUACA7AgoAkB0BBQDIjkGyVOwaOgCwPAIKWRNsAGqTLh4AIDsCCgCQHQEFAMiOgAIAZEdAAQCyYxYPLZ5r+gDUeAVlwoQJscsuu8QGG2wQXbt2jQMOOCBmzpxZdsxee+0VrVq1KtuOP/74smPeeuutGDZsWKy77rrF85x66qnx+eefr5lXBADUVgVl6tSpceKJJxYhJQWKM844I/bee+94+eWXY7311ms87thjj43zzjuv8X4KIg2++OKLIpx07949nnjiiXjvvffi8MMPj7XWWisuuuiiNfW6AIBaCSgPPvhg2f0bb7yxqIBMnz499txzz7JAkgLIsvztb38rAs3f//736NatW+y4445x/vnnx+mnnx7nnnturL322k19LQBAlfhKg2QXLFhQ3Hbu3Lns8VtuuSU23HDD6NevX4wbNy4++eSTxn3Tpk2L7bbbrggnDYYMGRJ1dXXx0ksvLfPnLFq0qNi/5AYAVK8mD5Ktr6+Pk08+OXbfffciiDT4+c9/Hptsskn07NkzXnjhhaIyksap3HnnncX+OXPmlIWTpOF+2re8sS/jx49valMBgFoJKGksyowZM+Lxxx8ve/y4445r/DpVSnr06BGDBg2K1157LbbYYosm/axUhRkzZkzj/VRB6dWrV1Obzldk1gwAWXbxjBw5Mu677754+OGHY+ONN17hsQMGDChuZ82aVdymsSlz584tO6bh/vLGrbRr1y46dOhQtgEA1Wu1KiilUilGjRoVd911VzzyyCOx2WabrfR7nn/++eI2VVKSgQMHxoUXXhjz5s0rBtgmkydPLkLHNtts07RXQXZXHK5kVSW39gDQzAEldetMmjQp7rnnnmItlIYxIx07doz27dsX3Thp/7777htdunQpxqCMHj26mOGz/fbbF8emackpiBx22GFx6aWXFs9x5plnFs+dKiUAAKvVxXPttdcWM3fSYmypItKw3XbbbcX+NEU4TR9OIaRPnz5xyimnxPDhw+Pee+9tfI42bdoU3UPpNlVTDj300GIdlCXXTQEAattqd/GsSBq4mhZzW5k0y+cvf/nL6vxoAKCGuFggAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQPVcLBBWd7l5AFhVKigAQHYEFAAgO7p4yIZuIQAaqKAAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7FjqnhUuN//GxcMq1hYAapcKCgCQHQEFAMiOgAIAZEdAAQCyY5AsNcHgX4CWRQUFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQnbaVbgB523Ts/ZVuAgA1SAUFAMiOgAIAZEdAAQCyI6AAANkRUACA7JjFU8PM0AEgVyooAEB2BBQAIDsCCgCQHQEFAGjZAWXChAmxyy67xAYbbBBdu3aNAw44IGbOnFl2zKeffhonnnhidOnSJdZff/0YPnx4zJ07t+yYt956K4YNGxbrrrtu8TynnnpqfP7552vmFQEAtRVQpk6dWoSPJ598MiZPnhyLFy+OvffeOxYuXNh4zOjRo+Pee++NO+64ozj+3XffjQMPPLBx/xdffFGEk88++yyeeOKJuOmmm+LGG2+Ms88+e82+MgCgxWpVKpVKTf3m999/v6iApCCy5557xoIFC2KjjTaKSZMmxUEHHVQc869//Sv69u0b06ZNi9122y0eeOCB+NGPflQEl27duhXHXHfddXH66acXz7f22muv9OfW1dVFx44di5/XoUOHpja/5tXyNOM3Lh5W6SYA1Jy61fj7/ZXGoKQfkHTu3Lm4nT59elFVGTx4cOMxffr0id69excBJUm32223XWM4SYYMGVI0+qWXXvoqzQEAan2htvr6+jj55JNj9913j379+hWPzZkzp6iAdOrUqezYFEbSvoZjlgwnDfsb9i3LokWLiq1BCjMAQPVqckBJY1FmzJgRjz/+eDS3NDh3/Pjxzf5zqO3uLd0+APloUhfPyJEj47777ouHH344Nt5448bHu3fvXgx+nT9/ftnxaRZP2tdwzNKzehruNxyztHHjxhXdSQ3b7Nmzm9JsAKAaA0oaT5vCyV133RUPPfRQbLbZZmX7+/fvH2uttVZMmTKl8bE0DTlNKx44cGBxP92++OKLMW/evMZj0oygNFhmm222WebPbdeuXbF/yQ0AqF5tV7dbJ83Queeee4q1UBrGjKQRue3bty9ujznmmBgzZkwxcDYFiVGjRhWhJM3gSdK05BREDjvssLj00kuL5zjzzDOL505BBABgtQLKtddeW9zutddeZY/fcMMNceSRRxZfX3HFFdG6detigbY0sDXN0Lnmmmsaj23Tpk3RPXTCCScUwWW99daLI444Is4777w184oAgNpeB6VSrIOyZtTyOijLYpAsQJWsgwIA0BwEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA1XOxQKh2LigIUDkqKABAdgQUACA7AgoAkB0BBQDIjoACAGRHQAEAsiOgAADZEVAAgOxYqA1WsDAbAJWhggIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANlxLR5o5mv6vHHxsIq1BaClUkEBALKjglJDV+b1SR6AlkIFBQDIjoACAGRHF0+Nd/sAQI4EFFgNZugAfD108QAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI5pxvAVWFsGoHmooAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKANDyA8qjjz4a++23X/Ts2TNatWoVd999d9n+I488snh8yW2fffYpO+bDDz+MESNGRIcOHaJTp05xzDHHxMcff/zVXw1kesXjpTcA1nBAWbhwYeywww5x9dVXL/eYFEjee++9xu3WW28t25/CyUsvvRSTJ0+O++67rwg9xx133Oo2BQCoUm1X9xuGDh1abCvSrl276N69+zL3vfLKK/Hggw/GM888EzvvvHPx2MSJE2PfffeNyy+/vKjMAAC1rVnGoDzyyCPRtWvX2HrrreOEE06IDz74oHHftGnTim6dhnCSDB48OFq3bh1PPfXUMp9v0aJFUVdXV7YBANVrjQeU1L1z8803x5QpU+KSSy6JqVOnFhWXL774otg/Z86cIrwsqW3bttG5c+di37JMmDAhOnbs2Lj16tVrTTcbAGjJXTwrc/DBBzd+vd1228X2228fW2yxRVFVGTRoUJOec9y4cTFmzJjG+6mCIqQAQPVq9mnGm2++eWy44YYxa9as4n4amzJv3ryyYz7//PNiZs/yxq2kMS1pxs+SGwBQvZo9oLz99tvFGJQePXoU9wcOHBjz58+P6dOnNx7z0EMPRX19fQwYMKC5mwMAVGMXT1qvpKEakrz++uvx/PPPF2NI0jZ+/PgYPnx4UQ157bXX4rTTTotvfetbMWTIkOL4vn37FuNUjj322Ljuuuti8eLFMXLkyKJryAweAKBJFZRnn302dtppp2JL0tiQ9PXZZ58dbdq0iRdeeCH233//2GqrrYoF2Pr37x+PPfZY0U3T4JZbbok+ffoUY1LS9OI99tgjrr/+ev9HAICmVVD22muvKJVKy93/17/+daXPkSotkyZNWt0fDQDUCNfiAQCyI6AAANkRUACA7AgoAEB2BBQAoPqXuqcyNh17f6WbAABrjAoKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHbaVroBUIs2HXt/2f03Lh5WsbYA5EhAqYI/bgBQbXTxAADZEVAAgOzo4oFMGacC1DIVFAAgOwIKAJAdAQUAyI6AAgBkxyBZyIC1bQDKCSjQgkOMmT1AtdLFAwBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKANDyA8qjjz4a++23X/Ts2TNatWoVd999d9n+UqkUZ599dvTo0SPat28fgwcPjldffbXsmA8//DBGjBgRHTp0iE6dOsUxxxwTH3/88Vd/NVVq07H3l20AUO3aru43LFy4MHbYYYc4+uij48ADD/zS/ksvvTSuuuqquOmmm2KzzTaLs846K4YMGRIvv/xyrLPOOsUxKZy89957MXny5Fi8eHEcddRRcdxxx8WkSZOi1gkgANCEgDJ06NBiW5ZUPbnyyivjzDPPjB//+MfFYzfffHN069atqLQcfPDB8corr8SDDz4YzzzzTOy8887FMRMnTox99903Lr/88qIyAwDUtjU6BuX111+POXPmFN06DTp27BgDBgyIadOmFffTberWaQgnSTq+devW8dRTTy3zeRctWhR1dXVlGwBQvVa7grIiKZwkqWKypHS/YV+67dq1a3kj2raNzp07Nx6ztAkTJsT48ePXZFOhpi3dlfjGxcMq1haAFjuLZ9y4cbFgwYLGbfbs2ZVuEgDQUgJK9+7di9u5c+eWPZ7uN+xLt/PmzSvb//nnnxczexqOWVq7du2KGT9LbgBA9VqjXTxp1k4KGVOmTIkdd9yxeCyNF0ljS0444YTi/sCBA2P+/Pkxffr06N+/f/HYQw89FPX19cVYFWDV6aoBqtVqB5S0XsmsWbPKBsY+//zzxRiS3r17x8knnxwXXHBBbLnllo3TjNPMnAMOOKA4vm/fvrHPPvvEscceG9ddd10xzXjkyJHFDB8zeACAJgWUZ599Nr7//e833h8zZkxxe8QRR8SNN94Yp512WrFWSlrXJFVK9thjj2JaccMaKMktt9xShJJBgwYVs3eGDx9erJ0CAJC0KqXFS1qY1G2Upi+nAbPVNh7FQm18FavaxaNrCMj973eLmMUDANSWNTpIFsivAqc6ArREKigAQHYEFAAgOwIKAJAdY1CgypkZBrREKigAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDstK10A4DK23Ts/V967I2Lh1WkLQCJCgoAkB0VFGCVqLIAXycVFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDstK10A2rdpmPvr3QTACA7KigAQHYEFAAgOwIKAJAdAQUAyI6AAgBUf0A599xzo1WrVmVbnz59Gvd/+umnceKJJ0aXLl1i/fXXj+HDh8fcuXPXdDMAgBasWSoo2267bbz33nuN2+OPP964b/To0XHvvffGHXfcEVOnTo133303DjzwwOZoBgDQQjXLOiht27aN7t27f+nxBQsWxB//+MeYNGlS/OAHPygeu+GGG6Jv377x5JNPxm677dYczQGawBo9QNVVUF599dXo2bNnbL755jFixIh46623isenT58eixcvjsGDBzcem7p/evfuHdOmTWuOpgAALdAar6AMGDAgbrzxxth6662L7p3x48fHd7/73ZgxY0bMmTMn1l577ejUqVPZ93Tr1q3YtzyLFi0qtgZ1dXVrutkAQDUHlKFDhzZ+vf322xeBZZNNNonbb7892rdv36TnnDBhQhF0Wjolc6rdsn7H37h4WEXaArRszX4tnlQt2WqrrWLWrFnxwx/+MD777LOYP39+WRUlzeJZ1piVBuPGjYsxY8aUVVB69erV3E0HVkLoBlrsOigff/xxvPbaa9GjR4/o379/rLXWWjFlypTG/TNnzizGqAwcOHC5z9GuXbvo0KFD2QYAVK81XkH55S9/Gfvtt1/RrZOmEJ9zzjnRpk2bOOSQQ6Jjx45xzDHHFNWQzp07F0Fj1KhRRTgxgwcAaLaA8vbbbxdh5IMPPoiNNtoo9thjj2IKcfo6ueKKK6J169bFAm1p4OuQIUPimmuuWdPNAABasFalUqkULUwag5KqMWldlZbU3aO/nlpkkCzQlL/frsUDAGRHQAEAsiOgAAC1tw4KwOqOzzJuBRBQgGYlfABNoYsHAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANlxsUCgohcPBFgWFRQAIDsCCgCQHV08QIvsGnrj4mEVawvQ/ASUZqSvHQCaRhcPAJAdAQUAyI6AAgBkxxgUoGoYSAvVQwUFAMiOgAIAZEdAAQCyYwzKGmLNE/h6+TcH1U0FBQDIjoACAGRHQAEAsmMMCpAd40sAAQWoqaBj8TZoGXTxAADZEVAAgOzo4gFqiuv1QMsgoDSRQXwA0Hx08QAA2VFBAWqamT6QJxUUACA7KigAK6HKAl8/FRQAIDsCCgCQHV08AE1gPRVoXiooAEB2BBQAIDsCCgCQHQEFAMiOQbIAS3GtLag8AQWggou5NWU2kIXjqAW6eACA7KigAHxNdB3BqmtVKpVK0cLU1dVFx44dY8GCBdGhQ4eKtMEbDZAzXT609L/fFa2gXH311XHZZZfFnDlzYocddoiJEyfGrrvuGpVmhUigpVuVcSpN/aDlPZGqHoNy2223xZgxY+Kcc86J5557rggoQ4YMiXnz5lWqSQBArXfxDBgwIHbZZZf43e9+V9yvr6+PXr16xahRo2Ls2LEV7eLRfQOwfE2dabSy5/k6ZyeZCVUZ2XfxfPbZZzF9+vQYN25c42OtW7eOwYMHx7Rp0750/KJFi4qtQXphDS+0OdQv+qRZnhegGqzKe++qvI/2Hn3Hav+sfuf89UvHzBg/ZKXHrKnXtfRzL/2zm1O/VXjtq/p9q6I5XlvDOV6l2kipAt55553UstITTzxR9vipp55a2nXXXb90/DnnnFMcb7PZbDabLVr8Nnv27JVmhRYxzThVWtJ4lQapO+jDDz+MLl26RKtWrdZIokvdS7Nnz67YrKBcOTcr5vysmPOzfM7Nijk/1Xl+UuXko48+ip49e6702IoElA033DDatGkTc+fOLXs83e/evfuXjm/Xrl2xLalTp05rvF3pf3JL+h/9dXJuVsz5WTHnZ/mcmxVzfqrv/KQxKNnO4ll77bWjf//+MWXKlLKqSLo/cODASjQJAMhIxbp4UpfNEUccETvvvHOx9smVV14ZCxcujKOOOqpSTQIAaj2g/OxnP4v3338/zj777GKhth133DEefPDB6Nat29feltR9lNZjWbobCedmZZyfFXN+ls+5WTHnZ8Vq4fy0yKXuAYDq5mrGAEB2BBQAIDsCCgCQHQEFAMhOzQaUCRMmFBcr3GCDDaJr165xwAEHxMyZMyvdrGxdfPHFxaq9J598cqWbko133nknDj300GJF4/bt28d2220Xzz77bNS6L774Is4666zYbLPNivOyxRZbxPnnn79q196oQo8++mjst99+xcqZ6d/Q3XffXbY/nZc0m7FHjx7F+UrXJHv11VejVqzo/CxevDhOP/304t/WeuutVxxz+OGHx7vvvhu14NGV/O4s6fjjjy+OSUt2VIuaDShTp06NE088MZ588smYPHly8Q9h7733LtZiodwzzzwTv//972P77bevdFOy8d///jd23333WGutteKBBx6Il19+OX7961/HN77xjah1l1xySVx77bXFlcpfeeWV4v6ll14aEydOjFqU3lN22GGHuPrqq5e5P52bq666Kq677rp46qmnij/EQ4YMiU8//TRq/fx88skn8dxzzxWBN93eeeedxQfJ/fffP2rBwpX87jS46667ir9lq7J8fIuyJi8C2JLNmzevuIDR1KlTK92UrHz00UelLbfcsjR58uTS9773vdJJJ51U6SZl4fTTTy/tsccelW5GloYNG1Y6+uijyx478MADSyNGjCjVuvQec9dddzXer6+vL3Xv3r102WWXNT42f/78Urt27Uq33nprqdbPz7I8/fTTxXFvvvlmqZbEcs7N22+/XfrmN79ZmjFjRmmTTTYpXXHFFaVqUbMVlKUtWLCguO3cuXOlm5KVVGUaNmxYUXbmf/785z8XqyD/5Cc/KboId9ppp/jDH/5Q6WZl4Tvf+U5x2Yp///vfxf1//vOf8fjjj8fQoUMr3bTsvP7668VClUv++0rXKRkwYEBMmzatom3L+b06dWU0x/XYWpr6+vo47LDD4tRTT41tt902qk2LuJrx1/E/OY2tSCX7fv36Vbo52fjTn/5UlFVTFw/l/vOf/xTdGOmSDWeccUZxjn7xi18U15lKl3CoZWPHji2utNqnT5/ioqBpTMqFF14YI0aMqHTTspPCSbL0CtrpfsM+/id1e6UxKYccckiLu0Bec7jkkkuibdu2xXtPNRJQ/n+VYMaMGcWnPP6fdAnvk046qRifs84661S6OVmG2lRBueiii4r7qYKSfofSOIJaDyi333573HLLLTFp0qTiU93zzz9ffABI/eO1fm5oujRO8Kc//WkxqDh9OKh106dPj9/+9rfFh8hUUapGNd/FM3LkyLjvvvvi4Ycfjo033rjSzcnql3/evHnx7W9/u0joaUsDi9NgvvR1+lRcy9KMi2222abssb59+8Zbb70VtS6Vm1MV5eCDDy5mX6QS9OjRo4uZc5Tr3r17cTt37tyyx9P9hn38L5y8+eabxYcm1ZOIxx57rHiP7t27d+N7dDo/p5xySmy66aZRDWq2gpJS+KhRo4rRz4888kgxJZL/GTRoULz44otlj6UrTaeyfSqxptJ9LUvdgUtPS09jLjbZZJOodWnmRevW5Z990u9LqjpRLr3vpCCSxuykC6YmqXsszeY54YQTKt28rMJJmnqdPkimaf1EEfyXHhuYZn+lx9N7dTVoW8vdOqkEfc899xRroTT096YBamktglqXzsnS43HS9Mf05mCcThQVgTQYNHXxpDfPp59+Oq6//vpiq3Vp3YY05iR9sktdPP/4xz/iN7/5TRx99NFRiz7++OOYNWtW2cDY1O2VBuSnc5S6vy644ILYcssti8CSptSm7rC0NlOtn59UqTzooIOKboxU6U6V24b36rQ/jfmq5d+dLkuFtbTsQQq8W2+9dVSFUo1KL31Z2w033FDppmXLNONy9957b6lfv37FlNA+ffqUrr/++ko3KQt1dXXF70nv3r1L66yzTmnzzTcv/epXvyotWrSoVIsefvjhZb7XHHHEEY1Tjc8666xSt27dit+lQYMGlWbOnFmqFSs6P6+//vpy36vT99X6787Sqm2acav0n0qHJACAJdX8IFkAID8CCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIARG7+D9rMR7xznUdSAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:57:34.039420Z",
     "start_time": "2025-03-02T02:57:34.035743Z"
    }
   },
   "cell_type": "code",
   "source": "np.mean(errors), np.std(errors)",
   "id": "3b71940f10e517b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(5.271278711401725), np.float64(1.5217825026057599))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f92dcdecacaabdd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:59:03.839743Z",
     "start_time": "2025-03-02T02:59:03.824605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del model_auto\n",
    "model_auto = VAE(input_dim=512, hidden_dim=256, latent_dim=16).to(device)"
   ],
   "id": "bcaf147549596cb4",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T03:09:04.288582Z",
     "start_time": "2025-03-02T02:59:04.508170Z"
    }
   },
   "cell_type": "code",
   "source": "training_loop(model_auto, dataloader_train, dataloader_test, nf='best_model_var_autoenc16_resnet34.pt')",
   "id": "f647fb37e9f4a25e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Epoch train loss: 2561174.4706307924\n",
      "Epoch val loss: 1568.7532958984375\n",
      "Epoch: 10, Epoch train loss: 12.99547818990854\n",
      "Epoch val loss: 12.84809398651123\n",
      "Epoch: 20, Epoch train loss: 10.524449421809269\n",
      "Epoch val loss: 10.421215057373047\n",
      "Epoch: 30, Epoch train loss: 8.904625232403095\n",
      "Epoch val loss: 8.73473072052002\n",
      "Epoch: 40, Epoch train loss: 7.700018295874963\n",
      "Epoch val loss: 7.6282758712768555\n",
      "Epoch: 50, Epoch train loss: 6.86276806317843\n",
      "Epoch val loss: 6.769453525543213\n",
      "Epoch: 60, Epoch train loss: 6.151344812833345\n",
      "Epoch val loss: 6.075650691986084\n",
      "Epoch: 70, Epoch train loss: 5.8155412673950195\n",
      "Epoch val loss: 5.819329261779785\n",
      "Epoch: 80, Epoch train loss: 5.606172928443322\n",
      "Epoch val loss: 5.531447887420654\n",
      "Epoch: 90, Epoch train loss: 5.461621247805082\n",
      "Epoch val loss: 5.47310209274292\n",
      "Epoch: 100, Epoch train loss: 5.394410206721379\n",
      "Epoch val loss: 5.351639747619629\n",
      "Epoch: 110, Epoch train loss: 5.327469935783973\n",
      "Epoch val loss: 5.2388153076171875\n",
      "Epoch: 120, Epoch train loss: 5.297856257512019\n",
      "Epoch val loss: 5.251368999481201\n",
      "Epoch: 130, Epoch train loss: 5.285177010756272\n",
      "Epoch val loss: 5.265876770019531\n",
      "Epoch: 140, Epoch train loss: 5.633021134596604\n",
      "Epoch val loss: 5.666790008544922\n",
      "Epoch: 150, Epoch train loss: 5.317093995901255\n",
      "Epoch val loss: 5.300872802734375\n",
      "Epoch: 160, Epoch train loss: 5.2857136359581585\n",
      "Epoch val loss: 5.245482921600342\n",
      "Epoch: 170, Epoch train loss: 5.280096090756929\n",
      "Epoch val loss: 5.205499172210693\n",
      "Epoch: 180, Epoch train loss: 5.272253953493559\n",
      "Epoch val loss: 5.177559852600098\n",
      "Epoch: 190, Epoch train loss: 5.275880666879507\n",
      "Epoch val loss: 5.246672630310059\n",
      "Epoch: 200, Epoch train loss: 5.27112157528217\n",
      "Epoch val loss: 5.225830554962158\n",
      "Epoch: 210, Epoch train loss: 5.2786419575030985\n",
      "Epoch val loss: 5.2019243240356445\n",
      "Epoch: 220, Epoch train loss: 5.274026137131911\n",
      "Epoch val loss: 5.162006378173828\n",
      "Epoch: 230, Epoch train loss: 5.2754124861497145\n",
      "Epoch val loss: 5.243486404418945\n",
      "Epoch: 240, Epoch train loss: 5.278114282167875\n",
      "Epoch val loss: 5.139609336853027\n",
      "Epoch: 250, Epoch train loss: 5.275468496175913\n",
      "Epoch val loss: 5.223728179931641\n",
      "Epoch: 260, Epoch train loss: 5.275314881251409\n",
      "Epoch val loss: 5.221314430236816\n",
      "Epoch: 270, Epoch train loss: 5.274375732128437\n",
      "Epoch val loss: 5.204090118408203\n",
      "Epoch: 280, Epoch train loss: 5.272505136636587\n",
      "Epoch val loss: 5.170243263244629\n",
      "Epoch: 290, Epoch train loss: 5.2691324307368355\n",
      "Epoch val loss: 5.204160690307617\n",
      "Epoch: 300, Epoch train loss: 5.269108662238488\n",
      "Epoch val loss: 5.201761722564697\n",
      "Epoch: 310, Epoch train loss: 5.272843177501972\n",
      "Epoch val loss: 5.279533386230469\n",
      "Epoch: 320, Epoch train loss: 5.274908799391526\n",
      "Epoch val loss: 5.241397857666016\n",
      "Epoch: 330, Epoch train loss: 5.27938358600323\n",
      "Epoch val loss: 5.195934772491455\n",
      "Epoch: 340, Epoch train loss: 5.2763913961557245\n",
      "Epoch val loss: 5.167168617248535\n",
      "Epoch: 350, Epoch train loss: 5.277452322152945\n",
      "Epoch val loss: 5.241532325744629\n",
      "Epoch: 360, Epoch train loss: 5.270590268648588\n",
      "Epoch val loss: 5.243993282318115\n",
      "Epoch: 370, Epoch train loss: 5.2641359109144945\n",
      "Epoch val loss: 5.202932357788086\n",
      "Epoch: 380, Epoch train loss: 5.272157559028039\n",
      "Epoch val loss: 5.257366180419922\n",
      "Epoch: 390, Epoch train loss: 5.273105034461389\n",
      "Epoch val loss: 5.219222068786621\n",
      "Epoch: 400, Epoch train loss: 5.27248687010545\n",
      "Epoch val loss: 5.226346969604492\n",
      "Epoch: 410, Epoch train loss: 5.2726491047785835\n",
      "Epoch val loss: 5.159881591796875\n",
      "Epoch: 420, Epoch train loss: 5.277187860929049\n",
      "Epoch val loss: 5.289098739624023\n",
      "Epoch: 430, Epoch train loss: 5.285284299116868\n",
      "Epoch val loss: 5.235085487365723\n",
      "Epoch: 440, Epoch train loss: 5.272809762221116\n",
      "Epoch val loss: 5.323526382446289\n",
      "Epoch: 450, Epoch train loss: 5.274059662452111\n",
      "Epoch val loss: 5.274844646453857\n",
      "Epoch: 460, Epoch train loss: 5.278691511887771\n",
      "Epoch val loss: 5.294880390167236\n",
      "Epoch: 470, Epoch train loss: 5.275809434744028\n",
      "Epoch val loss: 5.26523494720459\n",
      "Epoch: 480, Epoch train loss: 5.277635684380164\n",
      "Epoch val loss: 5.265869140625\n",
      "Epoch: 490, Epoch train loss: 5.273933740762564\n",
      "Epoch val loss: 5.235699653625488\n",
      "Epoch: 500, Epoch train loss: 5.276955237755408\n",
      "Epoch val loss: 5.204288482666016\n",
      "Epoch: 510, Epoch train loss: 5.274737101334792\n",
      "Epoch val loss: 5.277782917022705\n",
      "Epoch: 520, Epoch train loss: 5.277502536773682\n",
      "Epoch val loss: 5.196794509887695\n",
      "Epoch: 530, Epoch train loss: 5.2754621872535115\n",
      "Epoch val loss: 5.240623474121094\n",
      "Epoch: 540, Epoch train loss: 5.278940787682166\n",
      "Epoch val loss: 5.161454200744629\n",
      "Epoch: 550, Epoch train loss: 5.275215148925781\n",
      "Epoch val loss: 5.225980281829834\n",
      "Epoch: 560, Epoch train loss: 5.273989824148325\n",
      "Epoch val loss: 5.188624382019043\n",
      "Epoch: 570, Epoch train loss: 5.277672107403095\n",
      "Epoch val loss: 5.277738094329834\n",
      "Epoch: 580, Epoch train loss: 5.2818181331341085\n",
      "Epoch val loss: 5.301196098327637\n",
      "Epoch: 590, Epoch train loss: 5.276337366837722\n",
      "Epoch val loss: 5.220522403717041\n",
      "Epoch: 600, Epoch train loss: 5.275576114654541\n",
      "Epoch val loss: 5.22500467300415\n",
      "Epoch: 610, Epoch train loss: 5.274254065293532\n",
      "Epoch val loss: 5.223381996154785\n",
      "Epoch: 620, Epoch train loss: 5.277006736168494\n",
      "Epoch val loss: 5.211142063140869\n",
      "Epoch: 630, Epoch train loss: 5.273979260371282\n",
      "Epoch val loss: 5.225879669189453\n",
      "Epoch: 640, Epoch train loss: 5.276822677025428\n",
      "Epoch val loss: 5.133033275604248\n",
      "Epoch: 650, Epoch train loss: 5.2768354415893555\n",
      "Epoch val loss: 5.22026252746582\n",
      "Epoch: 660, Epoch train loss: 5.273311651670015\n",
      "Epoch val loss: 5.205536365509033\n",
      "Epoch: 670, Epoch train loss: 5.273568080021785\n",
      "Epoch val loss: 5.2146315574646\n",
      "Epoch: 680, Epoch train loss: 5.2793540220994215\n",
      "Epoch val loss: 5.263660430908203\n",
      "Epoch: 690, Epoch train loss: 5.273699613717886\n",
      "Epoch val loss: 5.259033203125\n",
      "Epoch: 700, Epoch train loss: 5.273660916548509\n",
      "Epoch val loss: 5.257073402404785\n",
      "Epoch: 710, Epoch train loss: 5.276340264540452\n",
      "Epoch val loss: 5.219865322113037\n",
      "Epoch: 720, Epoch train loss: 5.273389669565054\n",
      "Epoch val loss: 5.182364463806152\n",
      "Epoch: 730, Epoch train loss: 5.276889067429763\n",
      "Epoch val loss: 5.243965148925781\n",
      "Epoch: 740, Epoch train loss: 5.272549152374268\n",
      "Epoch val loss: 5.21785831451416\n",
      "Epoch: 750, Epoch train loss: 5.271338976346529\n",
      "Epoch val loss: 5.2874040603637695\n",
      "Epoch: 760, Epoch train loss: 5.280491278721736\n",
      "Epoch val loss: 5.276132583618164\n",
      "Epoch: 770, Epoch train loss: 5.274076791910025\n",
      "Epoch val loss: 5.180065631866455\n",
      "Epoch: 780, Epoch train loss: 5.280189037322998\n",
      "Epoch val loss: 5.278448104858398\n",
      "Epoch: 790, Epoch train loss: 5.276762705582839\n",
      "Epoch val loss: 5.262808322906494\n",
      "Epoch: 800, Epoch train loss: 5.2732559350820685\n",
      "Epoch val loss: 5.220497131347656\n",
      "Epoch: 810, Epoch train loss: 5.275767986591045\n",
      "Epoch val loss: 5.222480297088623\n",
      "Epoch: 820, Epoch train loss: 5.277960263765776\n",
      "Epoch val loss: 5.282194137573242\n",
      "Epoch: 830, Epoch train loss: 5.275118130903977\n",
      "Epoch val loss: 5.293636322021484\n",
      "Epoch: 840, Epoch train loss: 5.275242035205547\n",
      "Epoch val loss: 5.2909626960754395\n",
      "Epoch: 850, Epoch train loss: 5.278219919938308\n",
      "Epoch val loss: 5.201536655426025\n",
      "Epoch: 860, Epoch train loss: 5.279539218315711\n",
      "Epoch val loss: 5.2288737297058105\n",
      "Epoch: 870, Epoch train loss: 5.278538080362173\n",
      "Epoch val loss: 5.24678897857666\n",
      "Epoch: 880, Epoch train loss: 5.2766403051523065\n",
      "Epoch val loss: 5.235668182373047\n",
      "Epoch: 890, Epoch train loss: 5.273525678194487\n",
      "Epoch val loss: 5.248586654663086\n",
      "Epoch: 900, Epoch train loss: 5.275464167961707\n",
      "Epoch val loss: 5.262910842895508\n",
      "Epoch: 910, Epoch train loss: 5.273449420928955\n",
      "Epoch val loss: 5.276389122009277\n",
      "Epoch: 920, Epoch train loss: 5.278410177964431\n",
      "Epoch val loss: 5.282891273498535\n",
      "Epoch: 930, Epoch train loss: 5.274668583503137\n",
      "Epoch val loss: 5.16363525390625\n",
      "Epoch: 940, Epoch train loss: 5.274415823129507\n",
      "Epoch val loss: 5.254932403564453\n",
      "Epoch: 950, Epoch train loss: 5.276105293860803\n",
      "Epoch val loss: 5.262598514556885\n",
      "Epoch: 960, Epoch train loss: 5.272774989788349\n",
      "Epoch val loss: 5.241198539733887\n",
      "Epoch: 970, Epoch train loss: 5.272738896883451\n",
      "Epoch val loss: 5.274950981140137\n",
      "Epoch: 980, Epoch train loss: 5.274593389951265\n",
      "Epoch val loss: 5.192659378051758\n",
      "Epoch: 990, Epoch train loss: 5.2696350537813625\n",
      "Epoch val loss: 5.319240093231201\n",
      "Epoch: 1000, Epoch train loss: 5.27643555861253\n",
      "Epoch val loss: 5.221680641174316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.104282379150391"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T03:09:48.214512Z",
     "start_time": "2025-03-02T03:09:48.199036Z"
    }
   },
   "cell_type": "code",
   "source": "model_auto.load_state_dict(torch.load('best_model_var_autoenc16_resnet34.pt', map_location=device, weights_only=False))",
   "id": "bc09afcb7781a89b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T03:09:49.336623Z",
     "start_time": "2025-03-02T03:09:48.959055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "errors = extract_error(model_auto, dataloader_train, dataloader_test)\n",
    "len(errors)"
   ],
   "id": "bd1c9071fa89aec6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7168"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T03:09:50.238449Z",
     "start_time": "2025-03-02T03:09:50.174033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(errors, bins=100)\n",
    "plt.show()"
   ],
   "id": "8a3495e9d438f630",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T03:10:04.881145Z",
     "start_time": "2025-03-02T03:10:04.877629Z"
    }
   },
   "cell_type": "code",
   "source": "np.mean(errors), np.std(errors)",
   "id": "36f7b0b526f3177",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(5.267144923065124), np.float64(1.5174283455900972))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "35342adc14fc220d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

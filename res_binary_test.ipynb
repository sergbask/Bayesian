{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:07.314873Z",
     "start_time": "2025-03-11T02:15:05.560724Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from datasets import Dataset, load_from_disk\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:07.328859Z",
     "start_time": "2025-03-11T02:15:07.316166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "id": "991aab753971d136",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:07.330836Z",
     "start_time": "2025-03-11T02:15:07.329457Z"
    }
   },
   "cell_type": "code",
   "source": "path_final_test = './data/out_binary_test/'",
   "id": "6029196943079424",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:07.332603Z",
     "start_time": "2025-03-11T02:15:07.331303Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 128",
   "id": "dd136f4dd001ad15",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:07.541995Z",
     "start_time": "2025-03-11T02:15:07.539946Z"
    }
   },
   "cell_type": "code",
   "source": "preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],  std=[0.229, 0.224, 0.225])])",
   "id": "a07b6e36f80f6a71",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:08.102521Z",
     "start_time": "2025-03-11T02:15:08.097815Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset = ImageFolder(path_final_test, preprocess)",
   "id": "9cdd17c57c8a68c5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:08.790399Z",
     "start_time": "2025-03-11T02:15:08.786375Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset",
   "id": "6522743d1156c425",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 1683\n",
       "    Root location: ./data/out_binary_test/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
       "               CenterCrop(size=(224, 224))\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:09.211933Z",
     "start_time": "2025-03-11T02:15:09.210214Z"
    }
   },
   "cell_type": "code",
   "source": "testDataLoader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)",
   "id": "e52db9de1dd3f03e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:10.165045Z",
     "start_time": "2025-03-11T02:15:09.986678Z"
    }
   },
   "cell_type": "code",
   "source": "next(iter(testDataLoader))[1]",
   "id": "4df709ccf4f1758b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Naive:",
   "id": "93fe3fe669e52510"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:11.905195Z",
     "start_time": "2025-03-11T02:15:11.903294Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9cb1cdd4b62596f2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:13.032314Z",
     "start_time": "2025-03-11T02:15:12.634486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet34 = models.resnet34(weights=None)\n",
    "class CustomFC(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc1(x), x\n",
    "    \n",
    "resnet34.fc = CustomFC(512,8)\n",
    "resnet34.to(device)\n",
    "\n",
    "resnet34.load_state_dict(torch.load('model_best_resnet34.pt', map_location=device, weights_only=False))"
   ],
   "id": "5631019184d2569e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:13.524408Z",
     "start_time": "2025-03-11T02:15:13.521482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def naive_mod_acc(model, dataloader_test):\n",
    "    model.eval()\n",
    "    trg = []\n",
    "    pred = []\n",
    "    acc_test = 0.0\n",
    "    tot_test = 0.0\n",
    "    big_ones = 0.0\n",
    "    tot_positive = 0.0\n",
    "    with torch.no_grad():\n",
    "        for itms in dataloader_test:\n",
    "            x=itms[0]\n",
    "            target=itms[1]\n",
    "            x = x.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, _ = model(x)\n",
    "            outputs = outputs.sigmoid().max(dim=1).values\n",
    "            # print(outputs.shape)\n",
    "            acc_test += torch.sum(outputs.round() == target).item()\n",
    "            big_ones += torch.sum(outputs.round()).item()\n",
    "            pred.extend(outputs.round().cpu().tolist())\n",
    "            trg.extend(target.cpu().tolist())\n",
    "            tot_test += target.size(0)\n",
    "            tot_positive += torch.sum(target).item()\n",
    "        print(f'Test accuracy: {round(acc_test/tot_test*100,2)}%')\n",
    "        print(f'Higher than 50%: {round(big_ones/tot_test*100,2)}%')\n",
    "        print(f'Non-anomalies to total: {round(tot_positive/tot_test*100,2)}%')\n",
    "        \n",
    "    return round(acc_test/tot_test*100,2), round(big_ones/tot_test*100,2), pd.DataFrame({'true':trg, 'pred':pred})"
   ],
   "id": "a76986792c46f8e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:18.915528Z",
     "start_time": "2025-03-11T02:15:14.477579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_,_, res = naive_mod_acc(resnet34, testDataLoader)\n",
    "res"
   ],
   "id": "e98b1752ec6b9930",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 50.74%\n",
      "Higher than 50%: 97.68%\n",
      "Non-anomalies to total: 49.97%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      true  pred\n",
       "0        0   1.0\n",
       "1        0   1.0\n",
       "2        0   1.0\n",
       "3        1   1.0\n",
       "4        1   1.0\n",
       "...    ...   ...\n",
       "1678     1   1.0\n",
       "1679     1   1.0\n",
       "1680     1   1.0\n",
       "1681     1   1.0\n",
       "1682     1   1.0\n",
       "\n",
       "[1683 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1683 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Autoencoder",
   "id": "3d97a5a0e6a623b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:18.927329Z",
     "start_time": "2025-03-11T02:15:18.916362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, n, m, p, b):\n",
    "        super().__init__()\n",
    "        self.e1 = torch.nn.Linear(n, m)\n",
    "        self.e2 = torch.nn.Linear(m, p)\n",
    "        self.e3 = torch.nn.Linear(p, b)\n",
    "        self.dec3 = torch.nn.Linear(b, p)\n",
    "        self.dec2 = torch.nn.Linear(p, m)\n",
    "        self.dec1 = torch.nn.Linear(m, n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.e1(x)\n",
    "        x = self.e2(F.relu(x))\n",
    "        encoded = self.e3(F.relu(x))\n",
    "        x = self.dec3(encoded)\n",
    "        x = self.dec2(F.relu(x))\n",
    "        x = self.dec1(F.relu(x))\n",
    "        return x\n",
    "\n",
    "model_auto = AutoEncoder(512, 256, 128, 32)\n",
    "model_auto.to(device)\n",
    "model_auto.load_state_dict(torch.load('best_model_autoenc32_resnet34.pt', map_location=device, weights_only=False))"
   ],
   "id": "5b5925dc21a5527a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:24:13.392935Z",
     "start_time": "2025-03-11T02:24:13.388562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multy_mod_acc(model1, model2, dataloader_test, er_mean_rat=1.3):\n",
    "    loss_fn = torch.nn.MSELoss(reduction='none')\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    trg = []\n",
    "    pred = []\n",
    "    acc_test = 0.0\n",
    "    tot_test = 0.0\n",
    "    neg_ones = 0.0\n",
    "    tot_positive = 0.0\n",
    "    with torch.no_grad():\n",
    "        for itms in dataloader_test:\n",
    "            x=itms[0]\n",
    "            target=itms[1]\n",
    "            x = x.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, emb = model1(x)\n",
    "            x_pr = model2(emb)\n",
    "            error = torch.mean(loss_fn(x_pr, emb), dim=1)\n",
    "            prob = torch.exp(-torch.pow(error,2.)/(er_mean_rat*0.0026712)**2/2)\n",
    "            outputs = (prob*outputs.sigmoid().max(dim=1).values)\n",
    "            acc_test += torch.sum(outputs.round() == target).item()\n",
    "            neg_ones += torch.sum((outputs.round() == target)&(target == 1)).item()\n",
    "            # acc_test += torch.sum(torch.where(error>er_mean_rat,0,1) == target).item()\n",
    "            tot_test += target.size(0)\n",
    "            # \n",
    "            \n",
    "            # outputs = outputs.sigmoid().max(dim=1).values\n",
    "\n",
    "        #     big_ones += torch.sum(outputs.round()).item()\n",
    "        #     pred.extend(outputs.round().cpu().tolist())\n",
    "        #     trg.extend(target.cpu().tolist())\n",
    "        #     tot_test += target.size(0)\n",
    "        #     tot_positive += torch.sum(target).item()\n",
    "        # print(f'{er_mean_rat}Test accuracy: {round(acc_test/tot_test*100,2)}%')\n",
    "        # print(f'Higher than 50%: {round(big_ones/tot_test*100,2)}%')\n",
    "        # print(f'Non-anomalies to total: {round(tot_positive/tot_test*100,2)}%')\n",
    "        \n",
    "    return round(acc_test/tot_test*100,2), neg_ones/tot_test*2#, round(big_ones/tot_test*100,2), pd.DataFrame({'true':trg, 'pred':pred})"
   ],
   "id": "4058086e3ddb05a0",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:15:24.482733Z",
     "start_time": "2025-03-11T02:15:20.516583Z"
    }
   },
   "cell_type": "code",
   "source": "multy_mod_acc(resnet34, model_auto, testDataLoader)",
   "id": "2480771aa52d23b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.86, 0.9792038027332145)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:24:20.929648Z",
     "start_time": "2025-03-11T02:24:16.680865Z"
    }
   },
   "cell_type": "code",
   "source": "multy_mod_acc(resnet34, model_auto, testDataLoader, er_mean_rat=(1.3+433/1000))",
   "id": "a9f21385be2a1809",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91.8, 0.8805704099821747)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# (91.8, 0.9554367201426025)",
   "id": "275a797388f6817a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T01:37:52.272259Z",
     "start_time": "2025-03-04T01:37:52.270188Z"
    }
   },
   "cell_type": "code",
   "source": "del model_auto",
   "id": "47e9d59cac3d3bea",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VAE",
   "id": "33db6daa2229c260"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:38:41.955363Z",
     "start_time": "2025-03-05T01:38:41.927895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder (VAE) class.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Dimensionality of the input data.\n",
    "        hidden_dim (int): Dimensionality of the hidden layer.\n",
    "        latent_dim (int): Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "                \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 8),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 8, latent_dim*2), # 2 for mean and variance.\n",
    "        )\n",
    "        # self.parametr = nn.Linear(latent_dim, 2 * latent_dim)\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 8),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 8, hidden_dim // 4),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 2),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Encodes the input data into the latent space.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            eps (float): Small value to avoid numerical instability.\n",
    "        \n",
    "        Returns:\n",
    "            torch.distributions.MultivariateNormal: Normal distribution of the encoded data.\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        # x = self.parametr(lat_x)\n",
    "        mu, logvar = torch.chunk(x, 2, dim=-1)\n",
    "        scale = self.softplus(logvar) + eps\n",
    "        scale_tril = torch.diag_embed(scale)\n",
    "        \n",
    "        return torch.distributions.MultivariateNormal(mu, scale_tril=scale_tril)\n",
    "        \n",
    "    def reparameterize(self, dist):\n",
    "        \"\"\"\n",
    "        Reparameterizes the encoded data to sample from the latent space.\n",
    "        \n",
    "        Args:\n",
    "            dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
    "        Returns:\n",
    "            torch.Tensor: Sampled data from the latent space.\n",
    "        \"\"\"\n",
    "        return dist.rsample()\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes the data from the latent space to the original input space.\n",
    "        \n",
    "        Args:\n",
    "            z (torch.Tensor): Data in the latent space.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed data in the original input space.\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the VAE.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            compute_loss (bool): Whether to compute the loss or not.\n",
    "        \n",
    "        Returns:\n",
    "            VAEOutput: VAE output dataclass.\n",
    "        \"\"\"\n",
    "        dist = self.encode(x)\n",
    "        z = self.reparameterize(dist)\n",
    "        recon_x = self.decode(z)\n",
    "        \n",
    "        # compute loss terms \n",
    "        loss_recon = F.mse_loss(recon_x, x, reduction='none').sum(-1).sqrt()#.mean()\n",
    "        std_normal = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros_like(z, device=z.device),\n",
    "            scale_tril=torch.eye(z.shape[-1], device=z.device).unsqueeze(0).expand(z.shape[0], -1, -1),\n",
    "        )\n",
    "        loss_kl = torch.distributions.kl.kl_divergence(dist, std_normal)#.mean()\n",
    "        # loss_kl = F.kl_div(z, lat_x, reduction='none').mean()\n",
    "                \n",
    "        loss = loss_recon + loss_kl\n",
    "        \n",
    "        return loss.mean(),loss_recon\n",
    "\n",
    "model_auto1 = VAE(input_dim=512, hidden_dim=256, latent_dim=32).to(device)\n",
    "model_auto1.load_state_dict(torch.load(f'best_model_var_autoenc32_resnet34.pt', map_location=device, weights_only=False))"
   ],
   "id": "51ca59026bddd9ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:38:43.869608Z",
     "start_time": "2025-03-05T01:38:43.865361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multy_mod_acc_var(model1, model2, dataloader_test, er_mean_rat=.7):\n",
    "    loss_fn = torch.nn.MSELoss(reduction='none')\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    trg = []\n",
    "    pred = []\n",
    "    acc_test = 0.0\n",
    "    tot_test = 0.0\n",
    "    neg_ones = 0.0\n",
    "    tot_positive = 0.0\n",
    "    with torch.no_grad():\n",
    "        for itms in dataloader_test:\n",
    "            x=itms[0]\n",
    "            target=itms[1]\n",
    "            x = x.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, emb = model1(x)\n",
    "            error = model2(emb)[1]\n",
    "            prob = 1-torch.exp(-torch.pow(error,2.)/(er_mean_rat*5.)**2/2)\n",
    "            outputs = (prob*outputs.sigmoid().max(dim=1).values)\n",
    "            acc_test += torch.sum(outputs.round() == target).item()\n",
    "            neg_ones += torch.sum((outputs.round() == target)&(target == 1)).item()\n",
    "            # acc_test += torch.sum(torch.where(error>er_mean_rat,0,1) == target).item()\n",
    "            tot_test += target.size(0)\n",
    "            # \n",
    "            \n",
    "            # outputs = outputs.sigmoid().max(dim=1).values\n",
    "\n",
    "        #     big_ones += torch.sum(outputs.round()).item()\n",
    "        #     pred.extend(outputs.round().cpu().tolist())\n",
    "        #     trg.extend(target.cpu().tolist())\n",
    "        #     tot_test += target.size(0)\n",
    "        #     tot_positive += torch.sum(target).item()\n",
    "        # print(f'{er_mean_rat}Test accuracy: {round(acc_test/tot_test*100,2)}%')\n",
    "        # print(f'Higher than 50%: {round(big_ones/tot_test*100,2)}%')\n",
    "        # print(f'Non-anomalies to total: {round(tot_positive/tot_test*100,2)}%')\n",
    "        \n",
    "    return round(acc_test/tot_test*100,2), neg_ones/tot_test*2#, round(big_ones/tot_test*100,2), pd.DataFrame({'true':trg, 'pred':pred})\n",
    "\n"
   ],
   "id": "baeebe05d56a3f46",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:38:50.000517Z",
     "start_time": "2025-03-05T01:38:45.585720Z"
    }
   },
   "cell_type": "code",
   "source": "multy_mod_acc_var(resnet34, model_auto1, testDataLoader)",
   "id": "ba99d4e1e8ae8e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43.37, 0.6904337492572786)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## AE simple",
   "id": "4e02b0fae45ba5c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:40:05.374909Z",
     "start_time": "2025-03-05T01:40:05.353739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, n, m, p, b):\n",
    "        super().__init__()\n",
    "        self.e1 = torch.nn.Linear(n, m)\n",
    "        self.e2 = torch.nn.Linear(m, p)\n",
    "        self.e3 = torch.nn.Linear(p, b)\n",
    "        self.dec3 = torch.nn.Linear(b, p)\n",
    "        self.dec2 = torch.nn.Linear(p, m)\n",
    "        self.dec1 = torch.nn.Linear(m, n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.e1(x)\n",
    "        x = self.e2(F.relu(x))\n",
    "        encoded = self.e3(F.relu(x))\n",
    "        x = self.dec3(encoded)\n",
    "        x = self.dec2(F.relu(x))\n",
    "        x = self.dec1(F.relu(x))\n",
    "        return x\n",
    "\n",
    "model_auto = AutoEncoder(512, 256, 128, 32)\n",
    "model_auto.to(device)\n",
    "model_auto.load_state_dict(torch.load('best_model_autoenc32_resnet34.pt', map_location=device, weights_only=False))"
   ],
   "id": "80e25d771d8f5218",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:41:02.569555Z",
     "start_time": "2025-03-05T01:41:02.565303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sep_mod_acc(model1, model2, dataloader_test, er_mean_rat=1.3):\n",
    "    loss_fn = torch.nn.MSELoss(reduction='none')\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    trg = []\n",
    "    pred = []\n",
    "    acc_test = 0.0\n",
    "    tot_test = 0.0\n",
    "    neg_ones = 0.0\n",
    "    tot_positive = 0.0\n",
    "    with torch.no_grad():\n",
    "        for itms in dataloader_test:\n",
    "            x=itms[0]\n",
    "            target=itms[1]\n",
    "            x = x.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs, emb = model1(x)\n",
    "            x_pr = model2(emb)\n",
    "            error = torch.mean(loss_fn(x_pr, emb), dim=1)/0.0026712\n",
    "            acc_test += torch.sum(torch.where(error>er_mean_rat,0,1) == target).item()\n",
    "            neg_ones += torch.sum((torch.where(error>er_mean_rat,0,1) == target)&(target == 1)).item()\n",
    "            tot_test += target.size(0)\n",
    "            \n",
    "            \n",
    "            # outputs = outputs.sigmoid().max(dim=1).values\n",
    "\n",
    "        #     big_ones += torch.sum(outputs.round()).item()\n",
    "        #     pred.extend(outputs.round().cpu().tolist())\n",
    "        #     trg.extend(target.cpu().tolist())\n",
    "        #     tot_test += target.size(0)\n",
    "        #     tot_positive += torch.sum(target).item()\n",
    "        # print(f'{er_mean_rat}Test accuracy: {round(acc_test/tot_test*100,2)}%')\n",
    "        # print(f'Higher than 50%: {round(big_ones/tot_test*100,2)}%')\n",
    "        # print(f'Non-anomalies to total: {round(tot_positive/tot_test*100,2)}%')\n",
    "        \n",
    "    return round(acc_test/tot_test*100,2), neg_ones/tot_test*2#, round(big_ones/tot_test*100,2), pd.DataFrame({'true':trg, 'pred':pred})"
   ],
   "id": "87a4cdf92375a9e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:41:07.341754Z",
     "start_time": "2025-03-05T01:41:03.309235Z"
    }
   },
   "cell_type": "code",
   "source": "sep_mod_acc(resnet34, model_auto, testDataLoader)",
   "id": "e3ff0d0d47587b94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.39, 0.6250742721330956)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d9012f475bcef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
